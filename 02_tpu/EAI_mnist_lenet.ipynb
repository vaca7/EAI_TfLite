{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ab3b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "mnist = mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "# Normalize the pixels in 0.0~1.0 float\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dc8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "class mnist_lenet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(mnist_lenet, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters=10, kernel_size=[3,3], input_shape = (28,28,1), activation= 'relu')\n",
    "        self.pool1 = layers.MaxPooling2D(2, 2)\n",
    "        self.conv2 = layers.Conv2D(filters=20, kernel_size=[3,3], activation= 'relu')\n",
    "        self.pool2 = layers.MaxPooling2D(2, 2)\n",
    "        self.conv3 = layers.Conv2D(filters=30, kernel_size=[3,3], activation= 'relu')\n",
    "        self.flat = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(64, activation='relu')\n",
    "        self.dense2 = layers.Dense(10, activation='softmax')\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        net = self.conv1(x)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.dense2(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef7a74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 14:45:42.634307: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-10-29 14:45:42.635715: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 14:45:42.637660: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-10-29 14:45:43.168106: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-10-29 14:45:43.170877: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2496000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.2310 - accuracy: 0.9259\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 336s 6ms/step - loss: 0.0745 - accuracy: 0.9796\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 258s 4ms/step - loss: 0.0682 - accuracy: 0.9806\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 252s 4ms/step - loss: 0.0692 - accuracy: 0.9824\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 218s 4ms/step - loss: 0.0667 - accuracy: 0.9831\n",
      "Model: \"mnist_lenet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  5430      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  17344     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  650       \n",
      "=================================================================\n",
      "Total params: 25,344\n",
      "Trainable params: 25,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 15:11:32.885481: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_lenet/assets\n"
     ]
    }
   ],
   "source": [
    "# Train & save model in frozen(.pb) format.\n",
    "\n",
    "my_model = mnist_lenet()\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "my_model.fit(train_images, train_labels, batch_size=1, epochs=5, verbose=1)\n",
    "my_model.summary()\n",
    "my_model.save('mnist_lenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0787c567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 15:11:33.430029: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\n",
      "2024-10-29 15:11:33.430073: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\n",
      "2024-10-29 15:11:33.430077: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:325] Ignored change_concat_input_ranges.\n",
      "2024-10-29 15:11:33.432532: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: mnist_lenet\n",
      "2024-10-29 15:11:33.434858: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
      "2024-10-29 15:11:33.434922: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: mnist_lenet\n",
      "2024-10-29 15:11:33.435824: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-10-29 15:11:33.438888: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2024-10-29 15:11:33.440010: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2024-10-29 15:11:33.527149: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: mnist_lenet\n",
      "2024-10-29 15:11:33.530960: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 98738 microseconds.\n",
      "2024-10-29 15:11:33.559753: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-29 15:11:33.594116: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Load model and convert it for TensorFlow Lite (.tflite format)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model_path = 'mnist_lenet'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_path)\n",
    "tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c14fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104472"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Create folder to save model.\n",
    "tflite_models_dir = pathlib.Path(\"mnist_lenet\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"mnist_lenet.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ab3028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 15:13:53.028664: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\n",
      "2024-10-29 15:13:53.028712: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\n",
      "2024-10-29 15:13:53.028717: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:325] Ignored change_concat_input_ranges.\n",
      "2024-10-29 15:13:53.028806: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: mnist_lenet\n",
      "2024-10-29 15:13:53.029559: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
      "2024-10-29 15:13:53.029572: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: mnist_lenet\n",
      "2024-10-29 15:13:53.032620: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2024-10-29 15:13:53.107012: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: mnist_lenet\n",
      "2024-10-29 15:13:53.111131: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 82320 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# For Edge TPU.\n",
    "# You must quntize your model in INT8 precision.\n",
    "\n",
    "# Get representative data set for post-quantization.\n",
    "# The representative data set prevents accuracy drop while quantization.\n",
    "def representative_data_gen():\n",
    "    for image in train_images[:1000]:  # Use a subset of the dataset\n",
    "        # Resize the image to the input shape of your model\n",
    "        image = tf.image.resize(image, (28, 28))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        yield [image]\n",
    "\n",
    "model_path = 'mnist_lenet'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_path)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e897f149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31760"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Create folder to save model.\n",
    "tflite_models_dir = pathlib.Path(\"\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"mnist_lenet_quant.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "# Now, you can convert your quzntized model for Edge TPU with edgetpu_compiler.\n",
    "# follow https://coral.ai/docs/edgetpu/compiler/#download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e9b137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed98dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
